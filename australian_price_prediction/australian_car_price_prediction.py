# -*- coding: utf-8 -*-
"""Australian_car_price_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xeT74DkC8F61QZODY4dFxfOP_cWg03rl

# **Australian Vehicle Price Prediction**

# **Problem Definition**
The Australian automotive market is extensive and constantly changing, with vehicle prices affected by various factors including **make, model, year, mileage, fuel type, and location**. Accurate price predictions are essential for buyers, sellers, and businesses to make informed decisions. Unfortunately, the absence of a strong, data-driven system to estimate vehicle prices can lead to inefficiencies in the marketplace.

# **Objectives**
1. Understand the relationship between vehicle attributes (e.g., brand, mileage, age) and price.
2. Preprocess and clean the data to ensure it is ready for machine learning.
3. Build and evaluate a machine learning model capable of accurately predicting vehicle prices.
4. Deploy the model as a web application for real-time predictions.

#**Importing Required Libraries for this project**
"""

# Basic Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from scipy.stats import skew, kurtosis

# preprocessing
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, ShuffleSplit
from sklearn.pipeline import Pipeline

# Models
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
import xgboost as xgb
from xgboost import XGBRegressor


# Models Evaluation
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Saving Model
import json
import pickle
import joblib

# Set display options to show all columns
pd.set_option('display.max_columns', None)  # No limit on the number of columns displayed
pd.set_option('display.width', None)        # Adjust the width of the display to the width of the screen

"""# **Loading the data**"""

df = pd.read_csv(r"/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/Australian Vehicle Prices.csv")

"""# **Loading the Data Dictionary**"""

data_dictionary = pd.read_csv(r"/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/Australian_Vehicle_Price_data_dictionary.csv")

data_dictionary

df.head()

df.tail()

df.info()

df.isnull().sum()

df["Doors"].value_counts()

df["Seats"].unique()

filtered_df = df[df['Seats']==" 15 Seats"]
filtered_df

df.Brand.value_counts()

columns_to_drop = ["Model", "Title", "ColourExtInt", "Location", "Car/Suv", "Doors"]

df1 = df.drop(columns=columns_to_drop, axis=1)

df1.head()

df_combined = df[["BodyType"]].join(df[["Seats"]])
df_combined.head()

df_combined.groupby("BodyType")["Seats"].unique()

missing_seat_by_bodytype = df_combined[df_combined["Seats"].isnull()].groupby("BodyType").size()
missing_seat_by_bodytype

df1["Seats_count"] = df1["Seats"].str.extract("(\d+)").astype(float)

df1.head()

# Get the mode (most frequent value) of 'Seats' for each 'BodyType'
mode_seats_by_Bodytype = df1.groupby("BodyType")["Seats_count"].apply(lambda x: x.mode()[0])
mode_seats_by_Bodytype

df1["Seats_count"] = df1["Seats_count"].fillna(df1["BodyType"].map(mode_seats_by_Bodytype))

df1.dropna(subset="Seats_count",  inplace=True)

df1.dropna(subset="Price",  inplace=True)

df2 = df1.drop("Seats", axis=1)

df2.isnull().sum()

df2.info()

categorical_columns = ["Brand", "UsedOrNew", "Transmission", "Engine", "DriveType", "FuelType", "FuelConsumption", "Kilometres", "CylindersinEngine", "BodyType"]

df2.to_csv("/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/AustralianVehiclePrices_df2.csv")

df3 = pd.read_csv(r"/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/AustralianVehiclePrices_df2.csv")

df3.head()

df3.Transmission.value_counts()

df3["Engine_in_litre"] = df3["Engine"].str.extract(r"(\d+\.?\d*) L").astype(float)

df3["Engine_in_litre"].head(10)

df3["Cylinders_in_engine"] = df3["CylindersinEngine"].str.extract(r"(\d+) cyl").astype(float)

df3["Cylinders_in_engine"].isnull().sum()

df3.head(2)

df4 = df3.drop(columns=["Unnamed: 0", "Engine", "CylindersinEngine"], axis=1)

df4["FuelConsumption_Per100km"] = df4["FuelConsumption"].str.extract("(\d+\.?\d*) L").astype(float)

df4["FuelConsumption"].head()

df4["FuelConsumption_Per100km"].isnull().sum()

df4.drop("FuelConsumption", axis=1, inplace=True)

df4["Price"] = pd.to_numeric(df4["Price"], errors='coerce')

df4["Kilometres"] = pd.to_numeric(df4["Kilometres"], errors='coerce')

df4["Kilometres"].isnull().sum()

df4.info()

df4.DriveType.value_counts()

df4 = pd.get_dummies(df4, columns=["DriveType"], prefix="DriveType")

Drivetype_columns = ["DriveType_4WD", "DriveType_AWD", "DriveType_Front", "DriveType_Other", "DriveType_Rear"]

df4[["DriveType_Front", "DriveType_4WD", "DriveType_AWD", "DriveType_Rear", "DriveType_Other"]] = df4[["DriveType_Front", "DriveType_4WD", "DriveType_AWD", "DriveType_Rear", "DriveType_Other"]].astype(int)

df4.head()

df5 = df4[df4["Transmission"]!="-"]

df5 = pd.get_dummies(df5, columns=["Transmission"], prefix="Transmission")

df5[["Transmission_Automatic", "Transmission_Manual"]] = df5[["Transmission_Automatic", "Transmission_Manual"]].astype(int)

df5 = pd.get_dummies(df5, columns=["UsedOrNew"], prefix="vechile_history")

df5[["vechile_history_DEMO", "vechile_history_NEW", "vechile_history_USED"]] = df5[["vechile_history_DEMO", "vechile_history_NEW", "vechile_history_USED"]].astype(int)

df5.loc[df5["FuelType"]=="-", "FuelType"] = "Other"

df5["FuelType"].value_counts()

df5 = pd.get_dummies(df5, columns=["FuelType"], prefix="FuelType")

df5[["FuelType_Diesel", "FuelType_Electric", "FuelType_Hybrid", "FuelType_LPG", "FuelType_Leaded", "FuelType_Other", "FuelType_Premium", "FuelType_Unleaded"]] = df5[["FuelType_Diesel", "FuelType_Electric", "FuelType_Hybrid", "FuelType_LPG", "FuelType_Leaded", "FuelType_Other", "FuelType_Premium", "FuelType_Unleaded"]].astype(int)

df5.BodyType.unique()

df5 = pd.get_dummies(df5, columns=["BodyType"], prefix="BodyType")

dummy_columns = [col for col in df5.columns if col.startswith('BodyType')]
dummy_columns

df5[dummy_columns] = df5[dummy_columns].astype(int)

df5["Brand"].unique()

df5["Brand"] = df5["Brand"].str.strip()

le = LabelEncoder()

df5["Brands"] = le.fit_transform(df5["Brand"])

"""# **brand_mapping**"""

brand_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
len(brand_mapping)

df6 = df5.copy()

df6 = df6.drop(columns=["Brand"], axis=1)

df6["Price"] = df6["Price"].fillna(df6["Price"].mean())

sns.histplot(df6["Engine_in_litre"], kde=True)
plt.title("Histogram of Engine_in_litre")
plt.show()

# Box plot
sns.boxplot(x=df6["Engine_in_litre"])
plt.title("Box plot ofEngine_in_litre")
plt.show()

# Skewness and Kurtosis
skewness = df6["Engine_in_litre"].skew()
kurtosis = df6["Engine_in_litre"].kurtosis()

print(f"Skewness: {skewness}")
print(f"Kurtosis: {kurtosis}")

df6["Kilometres"] = df6["Kilometres"].fillna(df6["Kilometres"].median())

df6["FuelConsumption_Per100km"] = df6["FuelConsumption_Per100km"].fillna(df6["FuelConsumption_Per100km"].mean())

df6["Engine_in_litre"] = df6.groupby("Brands")["Engine_in_litre"].transform(lambda x: x.fillna(x.median()))

df6["Cylinders_in_engine"] = df6.groupby("Brands")["Cylinders_in_engine"].transform(lambda x: x.fillna(x.median()))

df7 = df6.copy()

df7.dropna(subset=["Engine_in_litre", "Cylinders_in_engine"], inplace=True)

df7.info()

"""# **Visualizing the outliers in the dataset**"""

plt.figure(figsize=(15, 10))
numeric_columns = df7.select_dtypes(include=['float64', 'int64']).columns

for i, col in enumerate(numeric_columns, 1):
  plt.subplot(6, 6, i)
  sns.boxplot(x=df7[col])
  plt.title(f"Box plot of {col}")
  plt.tight_layout()

df7.to_csv("/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/AustralianVehiclePrices_df7.csv", index=False)

brand_mapping

# Convert brand_mapping dictionary values from int64 to int
brand_mapping = {key: int(value) for key, value in brand_mapping.items()}

with open("/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/brand_mapping.json", "w") as file:
  json.dump(brand_mapping, file)
print("Dictionary exported as 'brands.json'")

df7 = pd.read_csv("/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/AustralianVehiclePrices_df7.csv")

df7.head()

df7.info()

kilometres_q1 = df7["Kilometres"].quantile(0.25)
kilometres_q3 = df7["Kilometres"].quantile(0.75)
kilometres_IQR = q3 - q1
lower_bound = q1-1.5*IQR
upper_bound = q3+1.5*IQR

# Remove outliers
def remove_outliers(df, cols):
  for col in cols:
    q1 = df[col].quantile(0.25)
    q3 = df[col].quantile(0.75)
    IQR = q3-q1
    # Calculate lower and upper bounds
    lower_bound = q1-1.5*IQR
    upper_bound = q3+1.5*IQR
    df = df[(df[col]>= lower_bound) & (df[col]<=upper_bound)]
  return df

columns = ['Kilometres', 'Price', 'Engine_in_litre', 'FuelConsumption_Per100km', 'Cylinders_in_engine', "Seats_count"]

df8 = remove_outliers(df7, columns)

df8

len(df7)-len(df8)

plt.figure(figsize=(15, 10))
numeric_columns = df8.select_dtypes(include=['float64', 'int64']).columns

for i, col in enumerate(numeric_columns, 1):
  plt.subplot(6, 6, i)
  sns.boxplot(x=df8[col])
  plt.title(f"Box plot of {col}")
  plt.tight_layout()

plt.figure(figsize=(10, 5))
sns.boxplot(x=df8["Kilometres"])
plt.title("Box plot of Kilometre")
plt.show()

q1 = df8['Kilometres'].quantile(0.25)
q3 = df8['Kilometres'].quantile(0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr

df9 = df8[(df8['Kilometres'] >= lower_bound) & (df8['Kilometres'] <= upper_bound)]

plt.figure(figsize=(10, 5))
sns.boxplot(x=df9["Kilometres"])
plt.title("Box plot of Kilometre")
plt.show()

df9.head()

q1 = df9['Price'].quantile(0.25)
q3 = df9['Price'].quantile(0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr

df10 = df9[(df9['Price'] >= lower_bound) & (df9['Price'] <= upper_bound)]

plt.figure(figsize=(10, 5))
sns.boxplot(x=df10["Price"])
plt.title("Box plot of Kilometre")
plt.show()

q1 = df10["FuelConsumption_Per100km"].quantile(0.25)
q3 = df10["FuelConsumption_Per100km"].quantile(0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr

outlier = df10[(df10["FuelConsumption_Per100km"] < lower_bound) | (df10["FuelConsumption_Per100km"] > upper_bound)]

len(outlier)

df11 = df10[(df10["FuelConsumption_Per100km"] >= lower_bound) & (df10["FuelConsumption_Per100km"] <= upper_bound)]

df11.shape

df.shape

df11.head()

X = df11.drop(columns=["Year", "Price"])
y = df11["Price"]

X.to_csv("/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/X_data.csv")

y.to_csv("/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/y_data.csv")

X = pd.read_csv("/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/X_data.csv")

X = X.drop(columns="Unnamed: 0", axis=1)

y = pd.read_csv("/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/y_data.csv")

y = y.drop(columns="Unnamed: 0", axis=1)

X.head()

y.head()

"""# **Standarization**"""

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""# **Train-Test Split**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_test.to_csv("/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/X_test_data.csv")

y_test.to_csv("/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/y_test_data.csv")

y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()

cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)

kfold_cv = KFold(n_splits=5, shuffle=True, random_state=42)

"""# **Model initization**"""

linear_model = LinearRegression()
svr_model = SVR()
decision_tree_model = DecisionTreeRegressor()
random_forest_model = RandomForestRegressor(random_state=42)
gb_model = GradientBoostingRegressor()
XGB_model = XGBRegressor()

Linear_scores = cross_val_score(linear_model, X_scaled, y_scaled, cv=kfold_cv)
print("Linear Regression Cross-validation scores:", Linear_scores)
print("Mean R² score:", np.mean(Linear_scores))

svr_model_scores = cross_val_score(svr_model, X_scaled, y_scaled, cv=kfold_cv)
print("SVR Cross-validation scores:", svr_model_scores)
print("Mean R² score:", np.mean(svr_model_scores))

Decision_tree_scores = cross_val_score(decision_tree_model, X, y, cv=kfold_cv)
print("Decision tree Cross-validation scores:", Decision_tree_scores)
print("Mean R² score:", np.mean(Decision_tree_scores))

RF_scores = cross_val_score(random_forest_model, X, y, cv=kfold_cv)
print("Random forest Cross-validation scores:", RF_scores)
print("Mean R² score:", np.mean(RF_scores))

gb_scores = cross_val_score(gb_model, X, y, cv=kfold_cv)
print("Gradient boosting Cross-validation scores:", gb_scores)
print("Mean R² score:", np.mean(gb_scores))

"""# **Hypertuning**"""

param_grid = {
    'n_estimators': [100, 200, 300],  # Number of trees
    'max_depth': [10, 20, 30, None],   # Maximum depth of each tree
    'min_samples_split': [2, 5, 10],   # Minimum samples to split
    'min_samples_leaf': [1, 2, 4],     # Minimum samples in leaf nodes
    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider for splitting
    'bootstrap': [True, False]         # Bootstrap sampling
}

rf_grid_search = GridSearchCV(estimator=random_forest_model, param_grid=param_grid, cv=kfold_cv, n_jobs=-1, verbose=2, scoring="r2")

rf_grid_search.fit(X, y)

# Get the best hyperparameters and score
print(f"Best hyperparameters: {rf_grid_search.best_params_}")
print(f"Best score (r2): {rf_grid_search.best_score_}")

random_forest_model2 = RandomForestRegressor(bootstrap=True, max_depth=20, max_features="sqrt", min_samples_leaf=1, min_samples_split=2, n_estimators=300)

RF_scores = cross_val_score(random_forest_model2, X, y, cv=kfold_cv)
print("Random forest Cross-validation scores:", RF_scores)
print("Mean R² score:", np.mean(RF_scores))

random_forest_model2.fit(X_train, y_train)

random_forest_model2.score(X_test, y_test)

"""# **Feature Importance**"""

feature_importance = random_forest_model2.feature_importances_
features = X.columns

importance_df = pd.DataFrame({"Feature":features, "Importance": feature_importance})
importance_df = importance_df.sort_values(by="Importance", ascending=False)

importance_df

plt.figure(figsize=(10, 6))
plt.barh(importance_df["Feature"], importance_df["Importance"], color="skyblue")
plt.xlabel("importance")
plt.ylabel("Features")
plt.title("Features Importance")
plt.gca().invert_yaxis()
plt.show()

df7 = pd.read_csv(r"/content/drive/MyDrive/Programming/Machine learning/Dataset/Regression_datasets/australian_vechicle_price/AustralianVehiclePrices_df7.csv")

df7["Seats_count"].unique()

X.columns

y_pred = random_forest_model2.predict(X_test)

y_test.values.min()

y_pred

mae = mean_absolute_error(y_test, y_pred)
print(mae)

maeprediction_df = pd.DataFrame(y_pred, columns=['Predicted_Price']).reset_index(drop=True)

prediction_df["actual values"] = y_test['Price'].reset_index(drop=True)

prediction_df["residuals"] = prediction_df["actual values"]-prediction_df["Predicted_Price"]

prediction_df.head()

"""# **Residuals checking**"""

sns.histplot(prediction_df["residuals"], kde=True, bins=30, color="blue")
plt.title('Residuals Distribution')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.axvline(0, color='red', linestyle='--')  # Mark zero residuals
plt.show()

prediction_df["residuals"].describe()

print("Skewness:", skew(prediction_df['residuals']))
print("Kurtosis:", kurtosis(prediction_df['residuals']))

outliers = prediction_df[(prediction_df['residuals'] < -10000) | (prediction_df['residuals'] > 10000)]
print(outliers)

"""# **New Prediction**"""

nput_data = np.array([[23031.0,5.0,2.0,4.0,6.3,0,1,0,0,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,29]])
input_data = np.array(input_data).reshape(1, -1)
predicted_price = random_forest_model2.predict(input_data)
predicted_price

"""# **Exporting  the model**"""

# save the model
joblib.dump(random_forest_model2, "vehicle_price_model.pkl")